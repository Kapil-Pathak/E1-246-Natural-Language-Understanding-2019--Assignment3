{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "from nltk.corpus import treebank\n",
    "from nltk import Nonterminal, Production\n",
    "from nltk import induce_pcfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Induce PCFG grammar from treebank data:\n"
     ]
    }
   ],
   "source": [
    "print(\"Induce PCFG grammar from treebank data:\")\n",
    "\n",
    "productions = []\n",
    "Leaves=set()\n",
    "for item in treebank.fileids():\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        tree.collapse_unary(collapsePOS = False)# Remove branches A-B-C into A-B+C\n",
    "        tree.chomsky_normal_form(horzMarkov = 2)# Remove A->(B,C,D) into A->B,C+D->D\n",
    "        productions += tree.productions()\n",
    "        for i in range(len(tree.leaves())):\n",
    "            Leaves.add(tree.leaves()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Leaves=list(Leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk  import Nonterminal\n",
    "S = Nonterminal('S')\n",
    "grammar = induce_pcfg(S, productions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "S\n",
      "NP-SBJ\n",
      "S|<VP-.>\n",
      "NP-SBJ\n",
      "NP\n",
      "NP-SBJ|<,-ADJP>\n",
      "NP\n",
      "NNP\n",
      "NNP\n",
      "NNP\n",
      "Pierre\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "print(grammar.productions()[0].lhs())\n",
    "source=defaultdict()\n",
    "prob=defaultdict()\n",
    "rhs_1=set()\n",
    "lhs_1=set()\n",
    "total=set()\n",
    "for i in range(len(grammar.productions())):\n",
    "    q=len(grammar.productions()[i].rhs())\n",
    "    print(grammar.productions()[i].lhs())\n",
    "    A=str(grammar.productions()[i]).split(' -> ')[0]\n",
    "    \n",
    "    BC=str(grammar.productions()[i]).split(' -> ')[1].split()[:-1]\n",
    "    source[A]=BC\n",
    "    lhs_1.add(A)\n",
    "    total.add(A)\n",
    "    p1=float(str(grammar.productions()[i]).split(' -> ')[1].split()[-1][1:-1])\n",
    "    if len(BC)==1:\n",
    "        prob[str(grammar.productions()[i]).split(' -> ')[0]+\" -> \"+str(BC[0])]=p1\n",
    "        rhs_1.add(BC[0])\n",
    "        total.add(BC[0])\n",
    "        print(BC[0][1:-1])\n",
    "        break\n",
    "        print(BC[0])\n",
    "    elif len(BC)==2:\n",
    "        prob[str(grammar.productions()[i]).split(' -> ')[0]+\" -> \"+str(BC[0])+\" \"+str(BC[1])]=p1\n",
    "        rhs_1.add(BC[0])\n",
    "        rhs_1.add(BC[1])\n",
    "        print(BC[0])\n",
    "        print(BC[1])\n",
    "        total.add(BC[0])\n",
    "        total.add(BC[1])\n",
    "rhs_dict=defaultdict()\n",
    "lhs_dict=defaultdict()\n",
    "rhs_dict_r=defaultdict()\n",
    "lhs_dict_l=defaultdict()\n",
    "for i, item in enumerate(lhs_1):\n",
    "    lhs_dict[item]=i\n",
    "    lhs_dict_l[i]=item\n",
    "total_dict=defaultdict()\n",
    "reverse_dict=defaultdict()\n",
    "for i, item in enumerate(total):\n",
    "    total_dict[item]=i\n",
    "    reverse_dict[i]=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unary={}\n",
    "Binary={}\n",
    "for i in range(len(grammar.productions())):\n",
    "    if len(grammar.productions()[i].rhs())==1:\n",
    "        A=str(grammar.productions()[i]).split(' -> ')[0]\n",
    "        BC=str(grammar.productions()[i]).split(' -> ')[1].split()[:-1]\n",
    "        if A in Unary.keys():\n",
    "            Unary[A].append(BC[0])\n",
    "        else:\n",
    "            Unary[A]=[]\n",
    "            Unary[A].append(BC[0])\n",
    "    else:\n",
    "        A=str(grammar.productions()[i]).split(' -> ')[0]\n",
    "        BC=str(grammar.productions()[i]).split(' -> ')[1].split()[:-1]\n",
    "        if A in Binary.keys():\n",
    "            Binary[A].append(BC)\n",
    "        else:\n",
    "            Binary[A]=[]\n",
    "            Binary[A].append(BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict['VP|<VP-PP>']\n",
    "total1=list(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "sent=\"'I' 'saw' 'John' 'with' 'my' 'eyes'\"\n",
    "sent=sent.split(\" \")\n",
    "print(sent)\n",
    "nonterms=['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP$','RB','RBR','RBS','RP','SYM','TO','UH','VBD','VB','VBG','VBN','VBP','VBZ','WDT','WP','WP$','WRB']\n",
    "nonterm=len(lhs_1)\n",
    "score = [ [ [0.0 for y in range(nonterm ) ] for x in range( len(sent) +1 ) ] for z in range(len(sent) +1)]\n",
    "back = [ [ [None for y in range( nonterm) ] for x in range( len(sent) +1 ) ] for z in range(len(sent) +1)]\n",
    "a=0\n",
    "for i in tqdm(range(len(sent))):\n",
    "    l=sent[i]\n",
    "    pks=set()\n",
    "    for A in tqdm(Unary.keys()):\n",
    "        for pk in prob.keys():    \n",
    "            if pk.split(' -> ')[1] in sent:\n",
    "                pks.add(pk.split(' -> ')[0])\n",
    "        if str(A+\" -> \"+l) in prob.keys():\n",
    "            score[i][i+1][lhs_dict[A]] = float(prob[str(A+' -> '+l)])\n",
    "            a+=1\n",
    "    #print(pks)\n",
    "    added=1\n",
    "    print(\"started\")\n",
    "    while added:\n",
    "        added=0\n",
    "        for k in tqdm(Unary.keys()):\n",
    "            for item in Unary[k]:\n",
    "                if item in lhs_dict.keys():\n",
    "                    if score[i][i+1][lhs_dict[item]]>0:\n",
    "                        p1=prob[str(k)+' -> '+item]*score[i][i+1][lhs_dict[item]]\n",
    "                        if p1>score[i][i+1][lhs_dict[k]]:\n",
    "                            score[i][i+1][lhs_dict[k]]=p1\n",
    "                            back[i][i+1][lhs_dict[k]]=item\n",
    "                            print(back[i][i+1][lhs_dict[k]])\n",
    "                            added=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score[5][6][lhs_dict['NNS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print([j for j, e in enumerate(score[i][6]) if e != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary['S']\n",
    "lhs_dict['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(sent))\n",
    "for span in tqdm(range(2,len(sent)+1)):\n",
    "    print(\"span:\"+str(span))\n",
    "    for begin in tqdm(range(len(sent)-span+1)):\n",
    "        end=begin+span\n",
    "        print(\"span: \"+str(span)+\" begin: \"+str(begin)+\" end: \"+str(end))\n",
    "        for split in tqdm(range(begin+1,end)):\n",
    "            print(\"span: \"+str(span)+\" begin: \"+str(begin)+\" end: \"+str(end)+\" split: \"+str(split))\n",
    "            print(\"Check in grammar\")\n",
    "            for k in Binary.keys():\n",
    "                for item in Binary[k]:\n",
    "                    if begin==0 and end==6:\n",
    "                        if item[0] in lhs_dict.keys() and item[1] in lhs_dict.keys():\n",
    "                            p1=score[begin][split][lhs_dict[item[0]]]*score[split][end][lhs_dict[item[1]]]*prob[str(k)+' -> '+item[0]+\" \"+item[1]]\n",
    "                            print(score[begin][split][lhs_dict[item[0]]],score[split][end][lhs_dict[item[1]]])\n",
    "                            if p1>score[begin][end][lhs_dict[A]]:\n",
    "                                print(p1)\n",
    "                                score[begin][end][lhs_dict[A]]=p1\n",
    "                                back[begin][end][lhs_dict[A]]=(split,item[0],item[1])\n",
    "                                print(back[begin][end][lhs_dict[A]])\n",
    "                                print(\"S: \"+k)\n",
    "                                print(begin,end)\n",
    "        added=1\n",
    "        while added:\n",
    "            added=0\n",
    "            for k in tqdm(Unary.keys()):\n",
    "                for item in Unary[k]:\n",
    "                    if item in lhs_dict.keys():\n",
    "                        if score[begin][end][lhs_dict[item]]>0:\n",
    "                            p1=prob[str(k)+' -> '+item]*score[begin][end][lhs_dict[item]]\n",
    "                            print(p1)\n",
    "                            if p1>score[begin][end][lhs_dict[k]]:\n",
    "                                score[begin][end][lhs_dict[k]]=p1\n",
    "                                back[begin][end][lhs_dict[k]]=item\n",
    "                                added=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarTree(object):\n",
    "    '''\n",
    "    Tree data structure used to represent the grammar tree output generated by the cky algorithm\n",
    "    '''\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def insertLeft(self, new_node):\n",
    "            self.left = new_node\n",
    "\n",
    "    def insertRight(self, new_node):\n",
    "            self.right = new_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "def print_level_order(head, queue = deque()):\n",
    "    if isinstance(head,str):\n",
    "        print(head)\n",
    "        return\n",
    "    print(head.data)\n",
    "    [queue.append(node) for node in [head.left, head.right] if node]\n",
    "    if queue:\n",
    "        print_level_order(queue.popleft(), queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(start,end,idx,back,non_terms):\n",
    "    '''\n",
    "    build_tree() builds tree from the backpointer matrix obtained in the cky() function\n",
    "    :param start: start index for tree\n",
    "    :param end: end index for tree\n",
    "    :param idx: index used to find non_terminal\n",
    "    :param back: the backpointer matrix\n",
    "    :param non_terms: a list of non-terminals\n",
    "    :return:\n",
    "    '''\n",
    "    tree = GrammarTree(non_terms[idx])\n",
    "    node = back[start][end][idx]\n",
    "    if isinstance(node,tuple):\n",
    "        split,left_rule,right_rule = node\n",
    "        tree.insertLeft(build_tree(start,split,left_rule,back,non_terms))\n",
    "        tree.insertRight(build_tree(split,end,right_rule,back,non_terms))\n",
    "        return tree\n",
    "\"\"\"\n",
    "    else:\n",
    "        if node>0:\n",
    "            tree.insertLeft(GrammarTree(non_terms[node]))\n",
    "        return tree\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse_tree(score, back,non_terms):\n",
    "    '''\n",
    "    get_parse_tree() calls the build_tree() method\n",
    "    :param score: score matrix\n",
    "    :param back: backpointer matrix\n",
    "    :param non_terms: list of non_terminals\n",
    "    :return: GrammarTree the final parse tree\n",
    "    '''\n",
    "    root_index = score[0][len(score)-1].index(max(score[0][len(score)-1]))\n",
    "    print(root_index)\n",
    "    print(score[0][len(score)-1][root_index])\n",
    "    tree = build_tree(0,len(score)-1,root_index,back,non_terms)\n",
    "    print(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=get_parse_tree(score,back,reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
